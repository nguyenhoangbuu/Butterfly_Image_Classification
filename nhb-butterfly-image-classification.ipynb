{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12289446,"sourceType":"datasetVersion","datasetId":3442424}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils ","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:24:07.655440Z","iopub.execute_input":"2025-08-02T21:24:07.655792Z","iopub.status.idle":"2025-08-02T21:24:18.588966Z","shell.execute_reply.started":"2025-08-02T21:24:07.655763Z","shell.execute_reply":"2025-08-02T21:24:18.587863Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25859 sha256=38aa9b448aa506cc49435933b0c472fd9cbcfb637bb80995b354986e8e9bec95\n  Stored in directory: /root/.cache/pip/wheels/85/cf/3a/e265e975a1e7c7e54eb3692d6aa4e2e7d6a3945d29da46f2d7\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom imutils import paths\nimport os\nlist_train = list(paths.list_images('/kaggle/input/butterfly-image-classification/train'))\nlist_test = list(paths.list_images('/kaggle/input/butterfly-image-classification/test'))\ntrain_set = pd.read_csv('/kaggle/input/butterfly-image-classification/Training_set.csv')\ntest_set = pd.read_csv('/kaggle/input/butterfly-image-classification/Testing_set.csv')","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:24:18.591137Z","iopub.execute_input":"2025-08-02T21:24:18.591879Z","iopub.status.idle":"2025-08-02T21:24:33.323944Z","shell.execute_reply.started":"2025-08-02T21:24:18.591843Z","shell.execute_reply":"2025-08-02T21:24:33.322958Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_set.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T20:06:04.991686Z","iopub.execute_input":"2025-08-01T20:06:04.991988Z","iopub.status.idle":"2025-08-01T20:06:05.006922Z","shell.execute_reply.started":"2025-08-01T20:06:04.991966Z","shell.execute_reply":"2025-08-01T20:06:05.006004Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"filename    6499\nlabel         75\ndtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"print(len(list_train))\nprint(train_set.shape)\nprint(len(list_test))\nprint(test_set.shape)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:06:07.064775Z","iopub.execute_input":"2025-08-01T20:06:07.065416Z","iopub.status.idle":"2025-08-01T20:06:07.070022Z","shell.execute_reply.started":"2025-08-01T20:06:07.065385Z","shell.execute_reply":"2025-08-01T20:06:07.069119Z"},"trusted":true},"outputs":[{"name":"stdout","text":"6499\n(6499, 2)\n2786\n(2786, 1)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(train_set.head())\nprint(test_set.head())","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:06:45.794200Z","iopub.execute_input":"2025-08-01T20:06:45.794563Z","iopub.status.idle":"2025-08-01T20:06:45.802854Z","shell.execute_reply.started":"2025-08-01T20:06:45.794538Z","shell.execute_reply":"2025-08-01T20:06:45.801984Z"},"trusted":true},"outputs":[{"name":"stdout","text":"      filename                     label\n0  Image_1.jpg          SOUTHERN DOGFACE\n1  Image_2.jpg                    ADONIS\n2  Image_3.jpg            BROWN SIPROETA\n3  Image_4.jpg                   MONARCH\n4  Image_5.jpg  GREEN CELLED CATTLEHEART\n      filename\n0  Image_1.jpg\n1  Image_2.jpg\n2  Image_3.jpg\n3  Image_4.jpg\n4  Image_5.jpg\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Train models","metadata":{}},{"cell_type":"markdown","source":"## Model1 SVM","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:08:24.575159Z","iopub.execute_input":"2025-08-01T20:08:24.575842Z","iopub.status.idle":"2025-08-01T20:08:32.604421Z","shell.execute_reply.started":"2025-08-01T20:08:24.575813Z","shell.execute_reply":"2025-08-01T20:08:32.603692Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train1 = []\nlabels1 = []\nfor i in list_train:\n    label = train_set[train_set['filename'] == i.split(os.path.sep)[-1]]['label'].values[0]\n    img = load_img(i,target_size = (32,32,3))\n    img = img_to_array(img)\n    img = img.flatten()\n    train1.append(img)\n    labels1.append(label)\ntrain1 = np.array(train1,dtype = 'float32')  \nlabels1 = np.array(labels1)\nenc = LabelEncoder().fit(labels1)\nlabels1 = enc.transform(labels1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:12:33.959290Z","iopub.execute_input":"2025-08-01T20:12:33.960054Z","iopub.status.idle":"2025-08-01T20:13:25.367897Z","shell.execute_reply.started":"2025-08-01T20:12:33.960025Z","shell.execute_reply":"2025-08-01T20:13:25.366857Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"test_data1 = []\ntest_label = []\nfor i in list_test:\n    label = i.split(os.path.sep)[-1]\n    img = load_img(i,target_size = (32,32,3))\n    img = img_to_array(img)\n    img = img.flatten()\n    test_data1.append(img)\n    test_label.append(label)\ntest_data1 = np.array(test_data1,dtype='float32')/255\ntest_label = np.array(test_label)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:13:54.418103Z","iopub.execute_input":"2025-08-01T20:13:54.418787Z","iopub.status.idle":"2025-08-01T20:14:14.413876Z","shell.execute_reply.started":"2025-08-01T20:13:54.418756Z","shell.execute_reply":"2025-08-01T20:14:14.412852Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"test_label = pd.DataFrame({'filename':test_label})","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:14.415817Z","iopub.execute_input":"2025-08-01T20:14:14.416094Z","iopub.status.idle":"2025-08-01T20:14:14.421462Z","shell.execute_reply.started":"2025-08-01T20:14:14.416070Z","shell.execute_reply":"2025-08-01T20:14:14.420412Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(train1[:5])\nprint(labels1[:5])","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:14.422610Z","iopub.execute_input":"2025-08-01T20:14:14.422952Z","iopub.status.idle":"2025-08-01T20:14:14.435926Z","shell.execute_reply.started":"2025-08-01T20:14:14.422922Z","shell.execute_reply":"2025-08-01T20:14:14.435013Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[[ 30.  42.  18. ...  24.  31.  15.]\n [118. 114.  69. ... 187. 212. 110.]\n [157. 161.  38. ... 231. 220. 200.]\n [174. 149. 118. ...  85.  81.  80.]\n [119. 155.  68. ... 166. 205. 124.]]\n[20 21 11  8 33]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"df1 = pd.DataFrame(train1)\ndf1['target'] = labels1\nx = df1.iloc[:,:-1]/255\ny = df1.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:14.438155Z","iopub.execute_input":"2025-08-01T20:14:14.438783Z","iopub.status.idle":"2025-08-01T20:14:14.517851Z","shell.execute_reply.started":"2025-08-01T20:14:14.438754Z","shell.execute_reply":"2025-08-01T20:14:14.516734Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"x.head()","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:14.519003Z","iopub.execute_input":"2025-08-01T20:14:14.519458Z","iopub.status.idle":"2025-08-01T20:14:14.546793Z","shell.execute_reply.started":"2025-08-01T20:14:14.519417Z","shell.execute_reply":"2025-08-01T20:14:14.545873Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       0         1         2         3         4         5         6     \\\n0  0.117647  0.164706  0.070588  0.113725  0.160784  0.066667  0.109804   \n1  0.462745  0.447059  0.270588  0.466667  0.435294  0.290196  0.458824   \n2  0.615686  0.631373  0.149020  0.619608  0.639216  0.145098  0.643137   \n3  0.682353  0.584314  0.462745  0.854902  0.784314  0.776471  0.784314   \n4  0.466667  0.607843  0.266667  0.478431  0.615686  0.286275  0.482353   \n\n       7         8         9     ...      3062      3063      3064      3065  \\\n0  0.156863  0.070588  0.101961  ...  0.050980  0.086275  0.113725  0.050980   \n1  0.419608  0.282353  0.454902  ...  0.482353  0.827451  0.909804  0.552941   \n2  0.654902  0.149020  0.654902  ...  0.741176  0.937255  0.858824  0.760784   \n3  0.713726  0.698039  0.580392  ...  0.062745  0.705882  0.690196  0.694118   \n4  0.623529  0.282353  0.470588  ...  0.121569  0.435294  0.545098  0.254902   \n\n       3066      3067      3068      3069      3070      3071  \n0  0.090196  0.117647  0.054902  0.094118  0.121569  0.058824  \n1  0.745098  0.831373  0.439216  0.733333  0.831373  0.431373  \n2  0.862745  0.784314  0.686275  0.905882  0.862745  0.784314  \n3  0.572549  0.545098  0.572549  0.333333  0.317647  0.313726  \n4  0.607843  0.745098  0.415686  0.650980  0.803922  0.486275  \n\n[5 rows x 3072 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>3062</th>\n      <th>3063</th>\n      <th>3064</th>\n      <th>3065</th>\n      <th>3066</th>\n      <th>3067</th>\n      <th>3068</th>\n      <th>3069</th>\n      <th>3070</th>\n      <th>3071</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.117647</td>\n      <td>0.164706</td>\n      <td>0.070588</td>\n      <td>0.113725</td>\n      <td>0.160784</td>\n      <td>0.066667</td>\n      <td>0.109804</td>\n      <td>0.156863</td>\n      <td>0.070588</td>\n      <td>0.101961</td>\n      <td>...</td>\n      <td>0.050980</td>\n      <td>0.086275</td>\n      <td>0.113725</td>\n      <td>0.050980</td>\n      <td>0.090196</td>\n      <td>0.117647</td>\n      <td>0.054902</td>\n      <td>0.094118</td>\n      <td>0.121569</td>\n      <td>0.058824</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.462745</td>\n      <td>0.447059</td>\n      <td>0.270588</td>\n      <td>0.466667</td>\n      <td>0.435294</td>\n      <td>0.290196</td>\n      <td>0.458824</td>\n      <td>0.419608</td>\n      <td>0.282353</td>\n      <td>0.454902</td>\n      <td>...</td>\n      <td>0.482353</td>\n      <td>0.827451</td>\n      <td>0.909804</td>\n      <td>0.552941</td>\n      <td>0.745098</td>\n      <td>0.831373</td>\n      <td>0.439216</td>\n      <td>0.733333</td>\n      <td>0.831373</td>\n      <td>0.431373</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.615686</td>\n      <td>0.631373</td>\n      <td>0.149020</td>\n      <td>0.619608</td>\n      <td>0.639216</td>\n      <td>0.145098</td>\n      <td>0.643137</td>\n      <td>0.654902</td>\n      <td>0.149020</td>\n      <td>0.654902</td>\n      <td>...</td>\n      <td>0.741176</td>\n      <td>0.937255</td>\n      <td>0.858824</td>\n      <td>0.760784</td>\n      <td>0.862745</td>\n      <td>0.784314</td>\n      <td>0.686275</td>\n      <td>0.905882</td>\n      <td>0.862745</td>\n      <td>0.784314</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.682353</td>\n      <td>0.584314</td>\n      <td>0.462745</td>\n      <td>0.854902</td>\n      <td>0.784314</td>\n      <td>0.776471</td>\n      <td>0.784314</td>\n      <td>0.713726</td>\n      <td>0.698039</td>\n      <td>0.580392</td>\n      <td>...</td>\n      <td>0.062745</td>\n      <td>0.705882</td>\n      <td>0.690196</td>\n      <td>0.694118</td>\n      <td>0.572549</td>\n      <td>0.545098</td>\n      <td>0.572549</td>\n      <td>0.333333</td>\n      <td>0.317647</td>\n      <td>0.313726</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.466667</td>\n      <td>0.607843</td>\n      <td>0.266667</td>\n      <td>0.478431</td>\n      <td>0.615686</td>\n      <td>0.286275</td>\n      <td>0.482353</td>\n      <td>0.623529</td>\n      <td>0.282353</td>\n      <td>0.470588</td>\n      <td>...</td>\n      <td>0.121569</td>\n      <td>0.435294</td>\n      <td>0.545098</td>\n      <td>0.254902</td>\n      <td>0.607843</td>\n      <td>0.745098</td>\n      <td>0.415686</td>\n      <td>0.650980</td>\n      <td>0.803922</td>\n      <td>0.486275</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3072 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train1,X_valid1,y_train1,y_valid1 = train_test_split(x, y, test_size = 0.2, random_state = 27,stratify = y) ","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:15.205419Z","iopub.execute_input":"2025-08-01T20:14:15.205782Z","iopub.status.idle":"2025-08-01T20:14:15.244132Z","shell.execute_reply.started":"2025-08-01T20:14:15.205754Z","shell.execute_reply":"2025-08-01T20:14:15.243186Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"pars = {'C' : [100],\n       'gamma' : [0.0001],\n       'kernel' : ['rbf']}\nsvc = svm.SVC(probability = True)\nmodel1 = GridSearchCV(svc,pars,verbose=10)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:17.569465Z","iopub.execute_input":"2025-08-01T20:14:17.570183Z","iopub.status.idle":"2025-08-01T20:14:17.574594Z","shell.execute_reply.started":"2025-08-01T20:14:17.570149Z","shell.execute_reply":"2025-08-01T20:14:17.573556Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model1.fit(X_train1,y_train1)\n","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:14:20.009077Z","iopub.execute_input":"2025-08-01T20:14:20.010069Z","iopub.status.idle":"2025-08-01T20:33:16.609022Z","shell.execute_reply.started":"2025-08-01T20:14:20.010037Z","shell.execute_reply":"2025-08-01T20:33:16.607905Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 1/5; 1/1] START C=100, gamma=0.0001, kernel=rbf.............................\n[CV 1/5; 1/1] END C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time= 3.0min\n[CV 2/5; 1/1] START C=100, gamma=0.0001, kernel=rbf.............................\n[CV 2/5; 1/1] END C=100, gamma=0.0001, kernel=rbf;, score=0.362 total time= 3.0min\n[CV 3/5; 1/1] START C=100, gamma=0.0001, kernel=rbf.............................\n[CV 3/5; 1/1] END C=100, gamma=0.0001, kernel=rbf;, score=0.346 total time= 3.0min\n[CV 4/5; 1/1] START C=100, gamma=0.0001, kernel=rbf.............................\n[CV 4/5; 1/1] END C=100, gamma=0.0001, kernel=rbf;, score=0.330 total time= 3.0min\n[CV 5/5; 1/1] START C=100, gamma=0.0001, kernel=rbf.............................\n[CV 5/5; 1/1] END C=100, gamma=0.0001, kernel=rbf;, score=0.341 total time= 3.0min\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(estimator=SVC(probability=True),\n             param_grid={'C': [100], 'gamma': [0.0001], 'kernel': ['rbf']},\n             verbose=10)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(probability=True),\n             param_grid={&#x27;C&#x27;: [100], &#x27;gamma&#x27;: [0.0001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(probability=True),\n             param_grid={&#x27;C&#x27;: [100], &#x27;gamma&#x27;: [0.0001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"pred1 = model1.predict(X_valid1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:33:16.610486Z","iopub.execute_input":"2025-08-01T20:33:16.610759Z","iopub.status.idle":"2025-08-01T20:33:38.551314Z","shell.execute_reply.started":"2025-08-01T20:33:16.610736Z","shell.execute_reply":"2025-08-01T20:33:38.550530Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print(model1.best_params_)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:33:38.552396Z","iopub.execute_input":"2025-08-01T20:33:38.552657Z","iopub.status.idle":"2025-08-01T20:33:38.557264Z","shell.execute_reply.started":"2025-08-01T20:33:38.552636Z","shell.execute_reply":"2025-08-01T20:33:38.556405Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(pred1[:5])","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:33:38.569782Z","iopub.execute_input":"2025-08-01T20:33:38.570018Z","iopub.status.idle":"2025-08-01T20:33:38.581245Z","shell.execute_reply.started":"2025-08-01T20:33:38.569999Z","shell.execute_reply":"2025-08-01T20:33:38.580462Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[11 17 41 10 54]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(accuracy_score(y_valid1,pred1))\nprint(classification_report(y_valid1,pred1))","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:33:38.582277Z","iopub.execute_input":"2025-08-01T20:33:38.582584Z","iopub.status.idle":"2025-08-01T20:33:38.605095Z","shell.execute_reply.started":"2025-08-01T20:33:38.582556Z","shell.execute_reply":"2025-08-01T20:33:38.604259Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0.3446153846153846\n              precision    recall  f1-score   support\n\n           0       0.71      0.56      0.63        18\n           1       0.82      0.60      0.69        15\n           2       0.10      0.13      0.11        15\n           3       0.62      0.29      0.40        17\n           4       0.48      0.67      0.56        18\n           5       0.23      0.45      0.31        20\n           6       0.32      0.50      0.39        20\n           7       0.28      0.29      0.29        17\n           8       0.19      0.25      0.22        16\n           9       0.14      0.24      0.18        17\n          10       0.57      0.53      0.55        15\n          11       0.14      0.18      0.16        17\n          12       0.28      0.25      0.26        20\n          13       0.32      0.44      0.37        18\n          14       0.53      0.59      0.56        17\n          15       0.27      0.37      0.31        19\n          16       0.36      0.24      0.29        17\n          17       0.54      0.68      0.60        19\n          18       0.29      0.29      0.29        17\n          19       0.22      0.28      0.24        18\n          20       0.02      0.06      0.03        17\n          21       0.00      0.00      0.00        18\n          22       0.17      0.16      0.16        19\n          23       0.38      0.25      0.30        20\n          24       0.40      0.14      0.21        14\n          25       0.25      0.16      0.19        19\n          26       0.25      0.37      0.30        19\n          27       0.25      0.22      0.24        18\n          28       0.25      0.26      0.26        19\n          29       0.57      0.50      0.53        16\n          30       0.36      0.33      0.34        15\n          31       0.22      0.12      0.16        16\n          32       0.33      0.26      0.29        19\n          33       0.50      0.56      0.53        18\n          34       0.37      0.41      0.39        17\n          35       0.18      0.12      0.15        16\n          36       0.50      0.42      0.46        19\n          37       0.61      0.69      0.65        16\n          38       0.27      0.19      0.22        16\n          39       0.67      0.13      0.22        15\n          40       0.20      0.35      0.26        17\n          41       0.16      0.29      0.21        17\n          42       0.40      0.40      0.40        15\n          43       0.25      0.16      0.19        19\n          44       0.44      0.22      0.30        18\n          45       0.59      0.77      0.67        26\n          46       0.42      0.29      0.34        17\n          47       0.67      0.42      0.52        19\n          48       0.43      0.20      0.27        15\n          49       0.29      0.12      0.17        16\n          50       0.75      0.17      0.27        18\n          51       0.69      0.65      0.67        17\n          52       0.54      0.41      0.47        17\n          53       0.45      0.53      0.49        17\n          54       0.53      0.59      0.56        17\n          55       0.27      0.25      0.26        16\n          56       0.17      0.17      0.17        18\n          57       0.38      0.33      0.36        15\n          58       0.33      0.31      0.32        16\n          59       0.41      0.37      0.39        19\n          60       0.35      0.33      0.34        18\n          61       0.57      0.24      0.33        17\n          62       0.41      0.45      0.43        20\n          63       0.20      0.18      0.19        17\n          64       0.59      0.45      0.51        22\n          65       0.23      0.39      0.29        18\n          66       0.41      0.41      0.41        17\n          67       0.23      0.18      0.20        17\n          68       0.19      0.35      0.24        17\n          69       0.67      0.27      0.38        15\n          70       0.76      0.76      0.76        17\n          71       0.44      0.25      0.32        16\n          72       0.40      0.43      0.41        14\n          73       0.50      0.33      0.40        15\n          74       0.50      0.27      0.35        15\n\n    accuracy                           0.34      1300\n   macro avg       0.38      0.34      0.35      1300\nweighted avg       0.38      0.34      0.35      1300\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"pred_test1 = model1.predict_proba(test_data1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:33:38.605991Z","iopub.execute_input":"2025-08-01T20:33:38.606217Z","iopub.status.idle":"2025-08-01T20:34:23.080922Z","shell.execute_reply.started":"2025-08-01T20:33:38.606184Z","shell.execute_reply":"2025-08-01T20:34:23.079873Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Model KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\npar2 = {'n_neighbors': [1,2]}\nkneig = KNeighborsClassifier()\nmodel2 = GridSearchCV(kneig,par2,verbose=10)\nmodel2.fit(X_train1,y_train1)\n","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:32.282833Z","iopub.execute_input":"2025-08-01T20:35:32.283527Z","iopub.status.idle":"2025-08-01T20:35:36.726633Z","shell.execute_reply.started":"2025-08-01T20:35:32.283496Z","shell.execute_reply":"2025-08-01T20:35:36.725792Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 2 candidates, totalling 10 fits\n[CV 1/5; 1/2] START n_neighbors=1...............................................\n[CV 1/5; 1/2] END ................n_neighbors=1;, score=0.167 total time=   0.6s\n[CV 2/5; 1/2] START n_neighbors=1...............................................\n[CV 2/5; 1/2] END ................n_neighbors=1;, score=0.172 total time=   0.4s\n[CV 3/5; 1/2] START n_neighbors=1...............................................\n[CV 3/5; 1/2] END ................n_neighbors=1;, score=0.155 total time=   0.4s\n[CV 4/5; 1/2] START n_neighbors=1...............................................\n[CV 4/5; 1/2] END ................n_neighbors=1;, score=0.161 total time=   0.4s\n[CV 5/5; 1/2] START n_neighbors=1...............................................\n[CV 5/5; 1/2] END ................n_neighbors=1;, score=0.167 total time=   0.4s\n[CV 1/5; 2/2] START n_neighbors=2...............................................\n[CV 1/5; 2/2] END ................n_neighbors=2;, score=0.123 total time=   0.5s\n[CV 2/5; 2/2] START n_neighbors=2...............................................\n[CV 2/5; 2/2] END ................n_neighbors=2;, score=0.145 total time=   0.4s\n[CV 3/5; 2/2] START n_neighbors=2...............................................\n[CV 3/5; 2/2] END ................n_neighbors=2;, score=0.128 total time=   0.4s\n[CV 4/5; 2/2] START n_neighbors=2...............................................\n[CV 4/5; 2/2] END ................n_neighbors=2;, score=0.124 total time=   0.4s\n[CV 5/5; 2/2] START n_neighbors=2...............................................\n[CV 5/5; 2/2] END ................n_neighbors=2;, score=0.137 total time=   0.4s\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': [1, 2]}, verbose=10)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={&#x27;n_neighbors&#x27;: [1, 2]}, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={&#x27;n_neighbors&#x27;: [1, 2]}, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"pred2 = model2.predict(X_valid1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:40.654911Z","iopub.execute_input":"2025-08-01T20:35:40.655306Z","iopub.status.idle":"2025-08-01T20:35:41.412700Z","shell.execute_reply.started":"2025-08-01T20:35:40.655266Z","shell.execute_reply":"2025-08-01T20:35:41.411757Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"print(model2.best_params_)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:42.304417Z","iopub.execute_input":"2025-08-01T20:35:42.305062Z","iopub.status.idle":"2025-08-01T20:35:42.309870Z","shell.execute_reply.started":"2025-08-01T20:35:42.305034Z","shell.execute_reply":"2025-08-01T20:35:42.308727Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'n_neighbors': 1}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"print(pred2[:5])","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:44.726195Z","iopub.execute_input":"2025-08-01T20:35:44.727043Z","iopub.status.idle":"2025-08-01T20:35:44.731465Z","shell.execute_reply.started":"2025-08-01T20:35:44.727014Z","shell.execute_reply":"2025-08-01T20:35:44.730619Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[12 41 64 10 54]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(accuracy_score(y_valid1,pred2))\nprint(classification_report(y_valid1,pred2))","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:46.507251Z","iopub.execute_input":"2025-08-01T20:35:46.508261Z","iopub.status.idle":"2025-08-01T20:35:46.527620Z","shell.execute_reply.started":"2025-08-01T20:35:46.508198Z","shell.execute_reply":"2025-08-01T20:35:46.526654Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"0.16307692307692306\n              precision    recall  f1-score   support\n\n           0       0.86      0.33      0.48        18\n           1       0.67      0.40      0.50        15\n           2       0.00      0.00      0.00        15\n           3       1.00      0.12      0.21        17\n           4       0.00      0.00      0.00        18\n           5       0.28      0.25      0.26        20\n           6       0.62      0.25      0.36        20\n           7       0.50      0.18      0.26        17\n           8       0.07      0.12      0.09        16\n           9       0.03      0.24      0.06        17\n          10       0.50      0.40      0.44        15\n          11       0.07      0.18      0.10        17\n          12       0.23      0.15      0.18        20\n          13       0.22      0.22      0.22        18\n          14       0.50      0.18      0.26        17\n          15       0.06      0.16      0.09        19\n          16       0.67      0.12      0.20        17\n          17       0.19      0.32      0.24        19\n          18       0.12      0.18      0.14        17\n          19       0.27      0.56      0.36        18\n          20       0.02      0.18      0.04        17\n          21       0.00      0.00      0.00        18\n          22       0.02      0.05      0.03        19\n          23       0.50      0.05      0.09        20\n          24       1.00      0.07      0.13        14\n          25       0.00      0.00      0.00        19\n          26       0.00      0.00      0.00        19\n          27       0.30      0.17      0.21        18\n          28       0.06      0.05      0.05        19\n          29       0.67      0.12      0.21        16\n          30       0.25      0.20      0.22        15\n          31       0.40      0.12      0.19        16\n          32       0.20      0.05      0.08        19\n          33       0.58      0.39      0.47        18\n          34       0.11      0.24      0.15        17\n          35       0.00      0.00      0.00        16\n          36       0.62      0.26      0.37        19\n          37       0.15      0.25      0.19        16\n          38       0.60      0.19      0.29        16\n          39       0.20      0.07      0.10        15\n          40       0.29      0.24      0.26        17\n          41       0.10      0.35      0.15        17\n          42       0.14      0.33      0.20        15\n          43       0.40      0.11      0.17        19\n          44       0.00      0.00      0.00        18\n          45       0.67      0.31      0.42        26\n          46       0.00      0.00      0.00        17\n          47       0.50      0.21      0.30        19\n          48       0.67      0.13      0.22        15\n          49       0.00      0.00      0.00        16\n          50       1.00      0.06      0.11        18\n          51       0.60      0.18      0.27        17\n          52       0.50      0.06      0.11        17\n          53       0.38      0.18      0.24        17\n          54       0.58      0.41      0.48        17\n          55       0.16      0.25      0.20        16\n          56       0.04      0.06      0.04        18\n          57       0.00      0.00      0.00        15\n          58       0.00      0.00      0.00        16\n          59       1.00      0.05      0.10        19\n          60       0.42      0.28      0.33        18\n          61       0.50      0.06      0.11        17\n          62       0.50      0.05      0.09        20\n          63       0.11      0.06      0.08        17\n          64       0.41      0.32      0.36        22\n          65       0.14      0.39      0.20        18\n          66       0.28      0.29      0.29        17\n          67       0.00      0.00      0.00        17\n          68       0.06      0.24      0.09        17\n          69       0.20      0.20      0.20        15\n          70       1.00      0.29      0.45        17\n          71       0.00      0.00      0.00        16\n          72       0.10      0.14      0.11        14\n          73       1.00      0.07      0.12        15\n          74       0.00      0.00      0.00        15\n\n    accuracy                           0.16      1300\n   macro avg       0.32      0.16      0.17      1300\nweighted avg       0.33      0.16      0.18      1300\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"pred_test2 = model2.predict_proba(test_data1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:51.799610Z","iopub.execute_input":"2025-08-01T20:35:51.800511Z","iopub.status.idle":"2025-08-01T20:35:52.814268Z","shell.execute_reply.started":"2025-08-01T20:35:51.800477Z","shell.execute_reply":"2025-08-01T20:35:52.813472Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Model Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:54.569983Z","iopub.execute_input":"2025-08-01T20:35:54.570851Z","iopub.status.idle":"2025-08-01T20:35:54.698909Z","shell.execute_reply.started":"2025-08-01T20:35:54.570820Z","shell.execute_reply":"2025-08-01T20:35:54.697943Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"par3 = {'n_estimators':[500],\n       'max_features':['sqrt'],\n       'max_depth':[19],\n       'criterion':['gini']}","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:56.134649Z","iopub.execute_input":"2025-08-01T20:35:56.134979Z","iopub.status.idle":"2025-08-01T20:35:56.139374Z","shell.execute_reply.started":"2025-08-01T20:35:56.134952Z","shell.execute_reply":"2025-08-01T20:35:56.138433Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"rfc = RandomForestClassifier(random_state=27)\nmodel3 = GridSearchCV(rfc,par3,verbose=10)\nmodel3.fit(X_train1,y_train1)\n","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:35:58.184509Z","iopub.execute_input":"2025-08-01T20:35:58.184817Z","iopub.status.idle":"2025-08-01T20:52:12.560587Z","shell.execute_reply.started":"2025-08-01T20:35:58.184794Z","shell.execute_reply":"2025-08-01T20:52:12.559711Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV 1/5; 1/1] START criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500\n[CV 1/5; 1/1] END criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500;, score=0.364 total time= 2.6min\n[CV 2/5; 1/1] START criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500\n[CV 2/5; 1/1] END criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500;, score=0.365 total time= 2.6min\n[CV 3/5; 1/1] START criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500\n[CV 3/5; 1/1] END criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500;, score=0.348 total time= 2.6min\n[CV 4/5; 1/1] START criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500\n[CV 4/5; 1/1] END criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500;, score=0.358 total time= 2.6min\n[CV 5/5; 1/1] START criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500\n[CV 5/5; 1/1] END criterion=gini, max_depth=19, max_features=sqrt, n_estimators=500;, score=0.337 total time= 2.6min\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(estimator=RandomForestClassifier(random_state=27),\n             param_grid={'criterion': ['gini'], 'max_depth': [19],\n                         'max_features': ['sqrt'], 'n_estimators': [500]},\n             verbose=10)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(random_state=27),\n             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;max_depth&#x27;: [19],\n                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [500]},\n             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(random_state=27),\n             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;max_depth&#x27;: [19],\n                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [500]},\n             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=27)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=27)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"pred3 = model3.predict(X_valid1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:52:12.562053Z","iopub.execute_input":"2025-08-01T20:52:12.562501Z","iopub.status.idle":"2025-08-01T20:52:12.996952Z","shell.execute_reply.started":"2025-08-01T20:52:12.562331Z","shell.execute_reply":"2025-08-01T20:52:12.996266Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"print(pred3[:5])","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:52:12.997882Z","iopub.execute_input":"2025-08-01T20:52:12.998100Z","iopub.status.idle":"2025-08-01T20:52:13.002987Z","shell.execute_reply.started":"2025-08-01T20:52:12.998080Z","shell.execute_reply":"2025-08-01T20:52:13.002038Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[12 17 41 70 54]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(model3.best_params_)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:52:13.004577Z","iopub.execute_input":"2025-08-01T20:52:13.004818Z","iopub.status.idle":"2025-08-01T20:52:13.015115Z","shell.execute_reply.started":"2025-08-01T20:52:13.004797Z","shell.execute_reply":"2025-08-01T20:52:13.014392Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'criterion': 'gini', 'max_depth': 19, 'max_features': 'sqrt', 'n_estimators': 500}\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"print(accuracy_score(y_valid1,pred3))\nprint(classification_report(y_valid1,pred3))","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:52:13.016102Z","iopub.execute_input":"2025-08-01T20:52:13.016585Z","iopub.status.idle":"2025-08-01T20:52:13.035177Z","shell.execute_reply.started":"2025-08-01T20:52:13.016562Z","shell.execute_reply":"2025-08-01T20:52:13.034400Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0.3384615384615385\n              precision    recall  f1-score   support\n\n           0       0.45      0.56      0.50        18\n           1       0.50      0.60      0.55        15\n           2       0.25      0.07      0.11        15\n           3       0.75      0.35      0.48        17\n           4       0.59      0.56      0.57        18\n           5       0.22      0.60      0.32        20\n           6       0.36      0.60      0.45        20\n           7       0.62      0.29      0.40        17\n           8       0.11      0.12      0.11        16\n           9       0.15      0.47      0.23        17\n          10       0.80      0.27      0.40        15\n          11       0.00      0.00      0.00        17\n          12       0.28      0.25      0.26        20\n          13       0.38      0.56      0.45        18\n          14       0.50      0.41      0.45        17\n          15       0.10      0.11      0.10        19\n          16       0.20      0.06      0.09        17\n          17       0.53      0.47      0.50        19\n          18       0.11      0.06      0.08        17\n          19       0.39      0.39      0.39        18\n          20       0.08      0.12      0.10        17\n          21       0.08      0.06      0.07        18\n          22       0.20      0.05      0.08        19\n          23       0.40      0.50      0.44        20\n          24       0.67      0.29      0.40        14\n          25       0.00      0.00      0.00        19\n          26       0.31      0.63      0.41        19\n          27       0.27      0.44      0.33        18\n          28       0.17      0.42      0.25        19\n          29       0.37      0.69      0.48        16\n          30       0.50      0.40      0.44        15\n          31       1.00      0.06      0.12        16\n          32       0.43      0.32      0.36        19\n          33       0.73      0.61      0.67        18\n          34       0.24      0.47      0.31        17\n          35       0.50      0.25      0.33        16\n          36       0.28      0.47      0.35        19\n          37       0.39      0.69      0.50        16\n          38       0.29      0.12      0.17        16\n          39       1.00      0.07      0.12        15\n          40       0.25      0.35      0.29        17\n          41       0.24      0.29      0.26        17\n          42       0.67      0.27      0.38        15\n          43       0.27      0.32      0.29        19\n          44       0.44      0.22      0.30        18\n          45       0.32      0.81      0.46        26\n          46       0.29      0.12      0.17        17\n          47       0.32      0.32      0.32        19\n          48       1.00      0.33      0.50        15\n          49       0.50      0.06      0.11        16\n          50       0.40      0.22      0.29        18\n          51       0.57      0.47      0.52        17\n          52       0.31      0.59      0.41        17\n          53       0.47      0.53      0.50        17\n          54       0.37      0.65      0.47        17\n          55       0.50      0.25      0.33        16\n          56       0.18      0.11      0.14        18\n          57       0.40      0.13      0.20        15\n          58       0.67      0.12      0.21        16\n          59       0.42      0.26      0.32        19\n          60       0.33      0.22      0.27        18\n          61       0.56      0.29      0.38        17\n          62       0.37      0.50      0.43        20\n          63       0.50      0.18      0.26        17\n          64       0.26      0.41      0.32        22\n          65       0.17      0.28      0.21        18\n          66       0.44      0.41      0.42        17\n          67       0.30      0.41      0.35        17\n          68       0.67      0.12      0.20        17\n          69       0.60      0.40      0.48        15\n          70       0.75      0.88      0.81        17\n          71       0.00      0.00      0.00        16\n          72       0.30      0.21      0.25        14\n          73       0.43      0.40      0.41        15\n          74       0.33      0.27      0.30        15\n\n    accuracy                           0.34      1300\n   macro avg       0.40      0.33      0.32      1300\nweighted avg       0.39      0.34      0.32      1300\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"pred_test3 = model3.predict_proba(test_data1)","metadata":{"execution":{"iopub.status.busy":"2025-08-01T20:52:13.036138Z","iopub.execute_input":"2025-08-01T20:52:13.036421Z","iopub.status.idle":"2025-08-01T20:52:13.828548Z","shell.execute_reply.started":"2025-08-01T20:52:13.036401Z","shell.execute_reply":"2025-08-01T20:52:13.827785Z"},"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"## Model Ensembled","metadata":{}},{"cell_type":"code","source":"#pred123 = (pred_test1 + pred_test2 + pred_test3)/3","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.540999Z","iopub.status.idle":"2023-08-22T01:20:16.541844Z","shell.execute_reply.started":"2023-08-22T01:20:16.541523Z","shell.execute_reply":"2023-08-22T01:20:16.541553Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pred123 = np.argmax(pred123,axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.543306Z","iopub.status.idle":"2023-08-22T01:20:16.544135Z","shell.execute_reply.started":"2023-08-22T01:20:16.543852Z","shell.execute_reply":"2023-08-22T01:20:16.543879Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test_label['label'] = enc.inverse_transform(pred123)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.545690Z","iopub.status.idle":"2023-08-22T01:20:16.546498Z","shell.execute_reply.started":"2023-08-22T01:20:16.546201Z","shell.execute_reply":"2023-08-22T01:20:16.546230Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission = pd.merge(test_set,test_label,how = 'left',on = 'filename')","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.548145Z","iopub.status.idle":"2023-08-22T01:20:16.548990Z","shell.execute_reply.started":"2023-08-22T01:20:16.548697Z","shell.execute_reply":"2023-08-22T01:20:16.548726Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission.to_csv('Testing_set.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.550562Z","iopub.status.idle":"2023-08-22T01:20:16.551405Z","shell.execute_reply.started":"2023-08-22T01:20:16.551130Z","shell.execute_reply":"2023-08-22T01:20:16.551159Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.553138Z","iopub.status.idle":"2023-08-22T01:20:16.554049Z","shell.execute_reply.started":"2023-08-22T01:20:16.553734Z","shell.execute_reply":"2023-08-22T01:20:16.553767Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model CNN DenseNet121","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\ntrain_data = []\ntrain_label = []\nfor i in list_train:\n    label = train_set[train_set['filename']==i.split(os.path.sep)[-1]]['label'].values[0]\n    image = load_img(i,target_size = (224,224,3))\n    image = img_to_array(image)\n    train_data.append(image)\n    train_label.append(label)\ntrain_data = np.array(train_data,dtype='float32')\ntrain_label = np.array(train_label)  ","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:24:33.325780Z","iopub.execute_input":"2025-08-02T21:24:33.326548Z","iopub.status.idle":"2025-08-02T21:25:17.315710Z","shell.execute_reply.started":"2025-08-02T21:24:33.326513Z","shell.execute_reply":"2025-08-02T21:25:17.314933Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_data = []\ntest_label = []\nfor i in list_test:\n    label = i.split(os.path.sep)[-1]\n    image = load_img(i,target_size = (224,224,3))\n    image = img_to_array(image)\n    test_data.append(image)\n    test_label.append(label)\ntest_data = np.array(test_data,dtype='float32')\ntest_label = np.array(test_label)","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:17.316827Z","iopub.execute_input":"2025-08-02T21:25:17.317069Z","iopub.status.idle":"2025-08-02T21:25:33.212228Z","shell.execute_reply.started":"2025-08-02T21:25:17.317046Z","shell.execute_reply":"2025-08-02T21:25:33.211526Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"test_label = pd.DataFrame({'filename':test_label})","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:33.214375Z","iopub.execute_input":"2025-08-02T21:25:33.214635Z","iopub.status.idle":"2025-08-02T21:25:33.219431Z","shell.execute_reply.started":"2025-08-02T21:25:33.214613Z","shell.execute_reply":"2025-08-02T21:25:33.218686Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications import EfficientNetV2L\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import AveragePooling2D, BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nimport math","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:33.220479Z","iopub.execute_input":"2025-08-02T21:25:33.220749Z","iopub.status.idle":"2025-08-02T21:25:33.232450Z","shell.execute_reply.started":"2025-08-02T21:25:33.220728Z","shell.execute_reply":"2025-08-02T21:25:33.231703Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"enc = LabelEncoder()\nenc.fit(train_label)\ntrain_label = enc.transform(train_label)\nprint(train_label[:2])","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:33.233357Z","iopub.execute_input":"2025-08-02T21:25:33.233581Z","iopub.status.idle":"2025-08-02T21:25:33.251134Z","shell.execute_reply.started":"2025-08-02T21:25:33.233561Z","shell.execute_reply":"2025-08-02T21:25:33.250204Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[20 21]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_label = tf.keras.utils.to_categorical(train_label,num_classes = 75)\nprint(train_label[:2])","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:33.252292Z","iopub.execute_input":"2025-08-02T21:25:33.252869Z","iopub.status.idle":"2025-08-02T21:25:33.258872Z","shell.execute_reply.started":"2025-08-02T21:25:33.252837Z","shell.execute_reply":"2025-08-02T21:25:33.258079Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0.]]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_label, test_size = 0.2, random_state = 27, stratify = train_label)","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:33.259813Z","iopub.execute_input":"2025-08-02T21:25:33.260117Z","iopub.status.idle":"2025-08-02T21:25:34.644909Z","shell.execute_reply.started":"2025-08-02T21:25:33.260095Z","shell.execute_reply":"2025-08-02T21:25:34.644171Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(len(X_train))\nprint(len(X_valid))\nprint(len(y_train))\nprint(len(y_valid))","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:34.645880Z","iopub.execute_input":"2025-08-02T21:25:34.646118Z","iopub.status.idle":"2025-08-02T21:25:34.650825Z","shell.execute_reply.started":"2025-08-02T21:25:34.646098Z","shell.execute_reply":"2025-08-02T21:25:34.649885Z"},"trusted":true},"outputs":[{"name":"stdout","text":"5199\n1300\n5199\n1300\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"gen = ImageDataGenerator(zoom_range = 0.2,\n                        height_shift_range = 0.2,\n                        width_shift_range = 0.2,\n                        rotation_range = 20,\n                        shear_range = 0.2,\n                        horizontal_flip = True,\n                        vertical_flip = True,\n                        fill_mode = 'nearest'\n                        )","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:25:34.653037Z","iopub.execute_input":"2025-08-02T21:25:34.653287Z","iopub.status.idle":"2025-08-02T21:25:34.661339Z","shell.execute_reply.started":"2025-08-02T21:25:34.653260Z","shell.execute_reply":"2025-08-02T21:25:34.660472Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nckp = ModelCheckpoint(\"model.keras\", save_best_only = True)\nest = EarlyStopping(monitor = \"val_loss\", patience = 13)\nred = ReduceLROnPlateau(monitor = 'val_loss', min_lr = 0.0000001, factor = 0.1, patience = 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:34.662205Z","iopub.execute_input":"2025-08-02T21:25:34.662433Z","iopub.status.idle":"2025-08-02T21:25:34.673908Z","shell.execute_reply.started":"2025-08-02T21:25:34.662414Z","shell.execute_reply":"2025-08-02T21:25:34.673044Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class GeM(tf.keras.layers.Layer):\n    def __init__(self, pool_size, init_norm=3.0, normalize=False, **kwargs):\n        self.pool_size = pool_size\n        self.init_norm = init_norm\n        self.normalize = normalize\n\n        super(GeM, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'pool_size': self.pool_size,\n            'init_norm': self.init_norm,\n            'normalize': self.normalize,\n        })\n        return config\n\n    def build(self, input_shape):\n        feature_size = input_shape[-1]\n        self.p = self.add_weight(name='norms', shape=(feature_size,),\n                                 initializer=tf.keras.initializers.constant(self.init_norm),\n                                 trainable=True)\n        super(GeM, self).build(input_shape)\n\n    def call(self, inputs):\n        x = inputs\n        x = tf.math.maximum(x, 1e-6)\n        x = tf.pow(x, self.p)\n\n        x = tf.nn.avg_pool(x, self.pool_size, self.pool_size, 'VALID')\n        x = tf.pow(x, 1.0 / self.p)\n\n        if self.normalize:\n            x = tf.nn.l2_normalize(x, 1)\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, input_shape[-1]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:34.675012Z","iopub.execute_input":"2025-08-02T21:25:34.675580Z","iopub.status.idle":"2025-08-02T21:25:34.683932Z","shell.execute_reply.started":"2025-08-02T21:25:34.675543Z","shell.execute_reply":"2025-08-02T21:25:34.683283Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )#(1,512)*(512,81313)\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)#(1,81313)*(1,81313) = (1,81313)\n        output *= self.s\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:34.684985Z","iopub.execute_input":"2025-08-02T21:25:34.685287Z","iopub.status.idle":"2025-08-02T21:25:34.697666Z","shell.execute_reply.started":"2025-08-02T21:25:34.685257Z","shell.execute_reply":"2025-08-02T21:25:34.697016Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nclass CustomDataGenerator(Sequence):\n    def __init__(self, features, labels, batch_size):\n        self.features = features\n        self.labels = labels\n        self.batch_size = batch_size\n    def __len__(self):\n        return len(self.features)//self.batch_size\n    def __getitem__(self,index):\n        features_batch = self.features[self.batch_size*index:self.batch_size*(index+1)]\n        labels_batch = self.labels[self.batch_size*index:self.batch_size*(index+1)]\n        input2 = np.argmax(labels_batch,axis = 1)\n        return (features_batch, input2), labels_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:34.698601Z","iopub.execute_input":"2025-08-02T21:25:34.698923Z","iopub.status.idle":"2025-08-02T21:25:34.709985Z","shell.execute_reply.started":"2025-08-02T21:25:34.698892Z","shell.execute_reply":"2025-08-02T21:25:34.709205Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train = CustomDataGenerator(X_train,y_train,64)\nvalid = CustomDataGenerator(X_valid,y_valid,64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:34.710925Z","iopub.execute_input":"2025-08-02T21:25:34.711140Z","iopub.status.idle":"2025-08-02T21:25:34.720800Z","shell.execute_reply.started":"2025-08-02T21:25:34.711121Z","shell.execute_reply":"2025-08-02T21:25:34.720104Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"label = Input(shape = ())\nbasemodel1 = DenseNet121(weights = 'imagenet',include_top = False, input_tensor = Input(shape = (224,224,3)))\nheadmodel1 = basemodel1.output\nheadmodel1 = GeM(7)(headmodel1)\nheadmodel1 = Flatten()(headmodel1)\nheadmodel1 = Dense(units=512,activation = 'relu')(headmodel1)\nheadmodel1 = BatchNormalization(name=\"dense_before_arcface\")(headmodel1)\nheadmodel1 = ArcMarginProduct(n_classes = 75)([headmodel1,label])\nheadmodel1 = Dense(units = 75,activation = 'softmax')(headmodel1)\nmodel_densenet = Model(inputs = [basemodel1.input,label], outputs = headmodel1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:34.721599Z","iopub.execute_input":"2025-08-02T21:25:34.721846Z","iopub.status.idle":"2025-08-02T21:25:42.126842Z","shell.execute_reply.started":"2025-08-02T21:25:34.721826Z","shell.execute_reply":"2025-08-02T21:25:42.126087Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29084464/29084464 [==============================] - 2s 0us/step\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"for i in basemodel1.layers:\n    i.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:25:42.127866Z","iopub.execute_input":"2025-08-02T21:25:42.128129Z","iopub.status.idle":"2025-08-02T21:25:42.140498Z","shell.execute_reply.started":"2025-08-02T21:25:42.128106Z","shell.execute_reply":"2025-08-02T21:25:42.139775Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model_densenet.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T17:30:32.224560Z","iopub.execute_input":"2025-08-02T17:30:32.225349Z","iopub.status.idle":"2025-08-02T17:30:33.109732Z","shell.execute_reply.started":"2025-08-02T17:30:32.225307Z","shell.execute_reply":"2025-08-02T17:30:33.108826Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n zero_padding2d_2 (ZeroPadding2  (None, 230, 230, 3)  0          ['input_4[0][0]']                \n D)                                                                                               \n                                                                                                  \n conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d_2[0][0]']       \n                                )                                                                 \n                                                                                                  \n conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n                                )                                                                 \n                                                                                                  \n conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n                                )                                                                 \n                                                                                                  \n zero_padding2d_3 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n D)                             )                                                                 \n                                                                                                  \n pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_3[0][0]']       \n                                                                                                  \n conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n ization)                                                                                         \n                                                                                                  \n conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n                                                                                                  \n conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n                                                                                                  \n conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n te)                                                              'conv2_block1_2_conv[0][0]']    \n                                                                                                  \n conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n                                                                                                  \n conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n                                                                                                  \n conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n te)                                                              'conv2_block2_2_conv[0][0]']    \n                                                                                                  \n conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n                                                                                                  \n conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n                                                                                                  \n conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n te)                                                              'conv2_block3_2_conv[0][0]']    \n                                                                                                  \n conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n                                                                                                  \n conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n                                                                                                  \n conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n te)                                                              'conv2_block4_2_conv[0][0]']    \n                                                                                                  \n conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n                                                                                                  \n conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n                                                                                                  \n conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n te)                                                              'conv2_block5_2_conv[0][0]']    \n                                                                                                  \n conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n                                                                                                  \n conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n                                                                                                  \n conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n te)                                                              'conv2_block6_2_conv[0][0]']    \n                                                                                                  \n pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n                                                                                                  \n pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n                                                                                                  \n pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n                                                                                                  \n pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n                                                                                                  \n conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n                                                                                                  \n conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n                                                                                                  \n conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n te)                                                              'conv3_block1_2_conv[0][0]']    \n                                                                                                  \n conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n                                                                                                  \n conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n                                                                                                  \n conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n te)                                                              'conv3_block2_2_conv[0][0]']    \n                                                                                                  \n conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n                                                                                                  \n conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n                                                                                                  \n conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n te)                                                              'conv3_block3_2_conv[0][0]']    \n                                                                                                  \n conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n                                                                                                  \n conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n                                                                                                  \n conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n te)                                                              'conv3_block4_2_conv[0][0]']    \n                                                                                                  \n conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n                                                                                                  \n conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n                                                                                                  \n conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n te)                                                              'conv3_block5_2_conv[0][0]']    \n                                                                                                  \n conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n                                                                                                  \n conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n                                                                                                  \n conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n te)                                                              'conv3_block6_2_conv[0][0]']    \n                                                                                                  \n conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n                                                                                                  \n conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n                                                                                                  \n conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n te)                                                              'conv3_block7_2_conv[0][0]']    \n                                                                                                  \n conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n                                                                                                  \n conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n                                                                                                  \n conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n te)                                                              'conv3_block8_2_conv[0][0]']    \n                                                                                                  \n conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n                                                                                                  \n conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n                                                                                                  \n conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n te)                                                              'conv3_block9_2_conv[0][0]']    \n                                                                                                  \n conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n                                                                                                  \n conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n                                                                                                  \n conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n ate)                                                             'conv3_block10_2_conv[0][0]']   \n                                                                                                  \n conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n                                                                                                  \n conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n                                                                                                  \n conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n ate)                                                             'conv3_block11_2_conv[0][0]']   \n                                                                                                  \n conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n                                                                                                  \n conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n                                                                                                  \n conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n ate)                                                             'conv3_block12_2_conv[0][0]']   \n                                                                                                  \n pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n                                                                                                  \n pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n                                                                                                  \n pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n                                                                                                  \n pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n                                                                                                  \n conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n                                                                                                  \n conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n                                                                                                  \n conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n te)                                                              'conv4_block1_2_conv[0][0]']    \n                                                                                                  \n conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n                                                                                                  \n conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n                                                                                                  \n conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n te)                                                              'conv4_block2_2_conv[0][0]']    \n                                                                                                  \n conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n                                                                                                  \n conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n                                                                                                  \n conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n te)                                                              'conv4_block3_2_conv[0][0]']    \n                                                                                                  \n conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n                                                                                                  \n conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n                                                                                                  \n conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n te)                                                              'conv4_block4_2_conv[0][0]']    \n                                                                                                  \n conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n                                                                                                  \n conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n                                                                                                  \n conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n te)                                                              'conv4_block5_2_conv[0][0]']    \n                                                                                                  \n conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n                                                                                                  \n conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n                                                                                                  \n conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n te)                                                              'conv4_block6_2_conv[0][0]']    \n                                                                                                  \n conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n                                                                                                  \n conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n                                                                                                  \n conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n te)                                                              'conv4_block7_2_conv[0][0]']    \n                                                                                                  \n conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n                                                                                                  \n conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n                                                                                                  \n conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n te)                                                              'conv4_block8_2_conv[0][0]']    \n                                                                                                  \n conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n                                                                                                  \n conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n                                                                                                  \n conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n te)                                                              'conv4_block9_2_conv[0][0]']    \n                                                                                                  \n conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n                                                                                                  \n conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n                                                                                                  \n conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n ate)                                                             'conv4_block10_2_conv[0][0]']   \n                                                                                                  \n conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n                                                                                                  \n conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n                                                                                                  \n conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n ate)                                                             'conv4_block11_2_conv[0][0]']   \n                                                                                                  \n conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n                                                                                                  \n conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n                                                                                                  \n conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n ate)                                                             'conv4_block12_2_conv[0][0]']   \n                                                                                                  \n conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n                                                                                                  \n conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n                                                                                                  \n conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n ate)                                                             'conv4_block13_2_conv[0][0]']   \n                                                                                                  \n conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n                                                                                                  \n conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n                                                                                                  \n conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n ate)                                                             'conv4_block14_2_conv[0][0]']   \n                                                                                                  \n conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n                                                                                                  \n conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n                                                                                                  \n conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n ate)                                                             'conv4_block15_2_conv[0][0]']   \n                                                                                                  \n conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n                                                                                                  \n conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n                                                                                                  \n conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n ate)                                                             'conv4_block16_2_conv[0][0]']   \n                                                                                                  \n conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n                                                                                                  \n conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n                                                                                                  \n conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n ate)                                                             'conv4_block17_2_conv[0][0]']   \n                                                                                                  \n conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n                                                                                                  \n conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n                                                                                                  \n conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n ate)                                                             'conv4_block18_2_conv[0][0]']   \n                                                                                                  \n conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n                                                                                                  \n conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n                                                                                                  \n conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n ate)                                                             'conv4_block19_2_conv[0][0]']   \n                                                                                                  \n conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n                                                                                                  \n conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n                                                                                                  \n conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n ate)                                                             'conv4_block20_2_conv[0][0]']   \n                                                                                                  \n conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n                                                                                                  \n conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n                                                                                                  \n conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n ate)                                                             'conv4_block21_2_conv[0][0]']   \n                                                                                                  \n conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n                                                                                                  \n conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n                                                                                                  \n conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n ate)                                                             'conv4_block22_2_conv[0][0]']   \n                                                                                                  \n conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n                                                                                                  \n conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n                                                                                                  \n conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n ate)                                                             'conv4_block23_2_conv[0][0]']   \n                                                                                                  \n conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n                                                                                                  \n conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n                                                                                                  \n conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n                                                                                                  \n pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n                                )                                                                 \n                                                                                                  \n pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n                                )                                                                 \n                                                                                                  \n pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n                                                                                                  \n pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n                                                                                                  \n conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n                                                                                                  \n conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n                                                                                                  \n conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n te)                                                              'conv5_block1_2_conv[0][0]']    \n                                                                                                  \n conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n                                                                                                  \n conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n                                                                                                  \n conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n te)                                                              'conv5_block2_2_conv[0][0]']    \n                                                                                                  \n conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n                                                                                                  \n conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n                                                                                                  \n conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n te)                                                              'conv5_block3_2_conv[0][0]']    \n                                                                                                  \n conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n                                                                                                  \n conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n                                                                                                  \n conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n te)                                                              'conv5_block4_2_conv[0][0]']    \n                                                                                                  \n conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n                                                                                                  \n conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n                                                                                                  \n conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n te)                                                              'conv5_block5_2_conv[0][0]']    \n                                                                                                  \n conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n                                                                                                  \n conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n                                                                                                  \n conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n te)                                                              'conv5_block6_2_conv[0][0]']    \n                                                                                                  \n conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n                                                                                                  \n conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n                                                                                                  \n conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n te)                                                              'conv5_block7_2_conv[0][0]']    \n                                                                                                  \n conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n                                                                                                  \n conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n                                                                                                  \n conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n te)                                                              'conv5_block8_2_conv[0][0]']    \n                                                                                                  \n conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n                                                                                                  \n conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n                                                                                                  \n conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n te)                                                              'conv5_block9_2_conv[0][0]']    \n                                                                                                  \n conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n                                                                                                  \n conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n                                                                                                  \n conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n ate)                                                             'conv5_block10_2_conv[0][0]']   \n                                                                                                  \n conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n                                                                                                  \n conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n                                                                                                  \n conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n ate)                                                             'conv5_block11_2_conv[0][0]']   \n                                                                                                  \n conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n                                                                                                  \n conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n                                                                                                  \n conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n ate)                                                             'conv5_block12_2_conv[0][0]']   \n                                                                                                  \n conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n                                                                                                  \n conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n                                                                                                  \n conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n ate)                                                             'conv5_block13_2_conv[0][0]']   \n                                                                                                  \n conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n                                                                                                  \n conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n                                                                                                  \n conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n ate)                                                             'conv5_block14_2_conv[0][0]']   \n                                                                                                  \n conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n                                                                                                  \n conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n                                                                                                  \n conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n ate)                                                             'conv5_block15_2_conv[0][0]']   \n                                                                                                  \n conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n                                                                                                  \n conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n                                                                                                  \n conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n ate)                                                             'conv5_block16_2_conv[0][0]']   \n                                                                                                  \n bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n                                                                                                  \n relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n                                                                                                  \n ge_m_1 (GeM)                   (None, 1, 1, 1024)   1024        ['relu[0][0]']                   \n                                                                                                  \n flatten_1 (Flatten)            (None, 1024)         0           ['ge_m_1[0][0]']                 \n                                                                                                  \n dense_2 (Dense)                (None, 512)          524800      ['flatten_1[0][0]']              \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 512)         2048        ['dense_2[0][0]']                \n rmalization)                                                                                     \n                                                                                                  \n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n arc_margin_product_1 (ArcMargi  (None, 75)          38400       ['batch_normalization_1[0][0]',  \n nProduct)                                                        'input_3[0][0]']                \n                                                                                                  \n dense_3 (Dense)                (None, 75)           5700        ['arc_margin_product_1[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 7,609,476\nTrainable params: 570,948\nNon-trainable params: 7,038,528\n__________________________________________________________________________________________________\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"lr = 0.0001\nEpochs = 99\nbatch_size = 64\nimport tensorflow as tf\nimport keras\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                initial_learning_rate = lr,\n                decay_steps = 10000,\n                decay_rate = 0.9)\nopt = Adam(learning_rate = lr_schedule)\nmodel_densenet.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n#keras.metrics.AUC(name = 'auc')\nmodel_densenet.fit(train,\n          validation_data = valid,\n         epochs = Epochs)","metadata":{"execution":{"iopub.status.busy":"2025-08-02T21:26:33.628391Z","iopub.execute_input":"2025-08-02T21:26:33.629239Z","iopub.status.idle":"2025-08-02T21:44:23.310125Z","shell.execute_reply.started":"2025-08-02T21:26:33.629207Z","shell.execute_reply":"2025-08-02T21:44:23.309260Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/99\n81/81 [==============================] - 21s 155ms/step - loss: 5.7229 - accuracy: 0.0424 - val_loss: 5.3387 - val_accuracy: 0.0562\nEpoch 2/99\n81/81 [==============================] - 11s 133ms/step - loss: 4.6314 - accuracy: 0.1154 - val_loss: 4.5619 - val_accuracy: 0.1281\nEpoch 3/99\n81/81 [==============================] - 11s 133ms/step - loss: 3.9668 - accuracy: 0.1892 - val_loss: 4.0565 - val_accuracy: 0.1914\nEpoch 4/99\n81/81 [==============================] - 11s 134ms/step - loss: 3.4605 - accuracy: 0.2483 - val_loss: 3.6827 - val_accuracy: 0.2273\nEpoch 5/99\n81/81 [==============================] - 11s 133ms/step - loss: 3.0337 - accuracy: 0.3229 - val_loss: 3.3594 - val_accuracy: 0.2672\nEpoch 6/99\n81/81 [==============================] - 11s 133ms/step - loss: 2.6843 - accuracy: 0.3804 - val_loss: 3.1044 - val_accuracy: 0.3117\nEpoch 7/99\n81/81 [==============================] - 11s 132ms/step - loss: 2.3712 - accuracy: 0.4361 - val_loss: 2.8955 - val_accuracy: 0.3508\nEpoch 8/99\n81/81 [==============================] - 11s 132ms/step - loss: 2.1049 - accuracy: 0.4936 - val_loss: 2.6945 - val_accuracy: 0.3797\nEpoch 9/99\n81/81 [==============================] - 11s 132ms/step - loss: 1.8688 - accuracy: 0.5471 - val_loss: 2.5482 - val_accuracy: 0.4070\nEpoch 10/99\n81/81 [==============================] - 11s 131ms/step - loss: 1.6696 - accuracy: 0.5947 - val_loss: 2.3910 - val_accuracy: 0.4422\nEpoch 11/99\n81/81 [==============================] - 11s 130ms/step - loss: 1.4895 - accuracy: 0.6373 - val_loss: 2.2770 - val_accuracy: 0.4500\nEpoch 12/99\n81/81 [==============================] - 11s 132ms/step - loss: 1.3351 - accuracy: 0.6777 - val_loss: 2.1708 - val_accuracy: 0.4672\nEpoch 13/99\n81/81 [==============================] - 11s 130ms/step - loss: 1.1962 - accuracy: 0.7112 - val_loss: 2.1067 - val_accuracy: 0.4805\nEpoch 14/99\n81/81 [==============================] - 11s 131ms/step - loss: 1.0701 - accuracy: 0.7454 - val_loss: 1.9959 - val_accuracy: 0.5117\nEpoch 15/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.9583 - accuracy: 0.7745 - val_loss: 1.9244 - val_accuracy: 0.5273\nEpoch 16/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.8560 - accuracy: 0.8094 - val_loss: 1.8722 - val_accuracy: 0.5281\nEpoch 17/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.7631 - accuracy: 0.8295 - val_loss: 1.7937 - val_accuracy: 0.5539\nEpoch 18/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.6848 - accuracy: 0.8503 - val_loss: 1.7617 - val_accuracy: 0.5461\nEpoch 19/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.6118 - accuracy: 0.8719 - val_loss: 1.7064 - val_accuracy: 0.5703\nEpoch 20/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.5440 - accuracy: 0.8941 - val_loss: 1.6682 - val_accuracy: 0.5852\nEpoch 21/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.4840 - accuracy: 0.9095 - val_loss: 1.6276 - val_accuracy: 0.5883\nEpoch 22/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.4316 - accuracy: 0.9269 - val_loss: 1.5987 - val_accuracy: 0.6016\nEpoch 23/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.3852 - accuracy: 0.9410 - val_loss: 1.5646 - val_accuracy: 0.6133\nEpoch 24/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.3431 - accuracy: 0.9518 - val_loss: 1.5226 - val_accuracy: 0.6258\nEpoch 25/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.3043 - accuracy: 0.9616 - val_loss: 1.5039 - val_accuracy: 0.6383\nEpoch 26/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.2706 - accuracy: 0.9707 - val_loss: 1.4888 - val_accuracy: 0.6375\nEpoch 27/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.2405 - accuracy: 0.9801 - val_loss: 1.4802 - val_accuracy: 0.6391\nEpoch 28/99\n81/81 [==============================] - 11s 130ms/step - loss: 0.2141 - accuracy: 0.9851 - val_loss: 1.4537 - val_accuracy: 0.6352\nEpoch 29/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.1905 - accuracy: 0.9900 - val_loss: 1.4372 - val_accuracy: 0.6508\nEpoch 30/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.1706 - accuracy: 0.9929 - val_loss: 1.4168 - val_accuracy: 0.6492\nEpoch 31/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.1518 - accuracy: 0.9944 - val_loss: 1.3997 - val_accuracy: 0.6617\nEpoch 32/99\n81/81 [==============================] - 11s 130ms/step - loss: 0.1361 - accuracy: 0.9965 - val_loss: 1.3873 - val_accuracy: 0.6586\nEpoch 33/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.1222 - accuracy: 0.9969 - val_loss: 1.3751 - val_accuracy: 0.6633\nEpoch 34/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.1104 - accuracy: 0.9981 - val_loss: 1.3571 - val_accuracy: 0.6648\nEpoch 35/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0996 - accuracy: 0.9985 - val_loss: 1.3516 - val_accuracy: 0.6641\nEpoch 36/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0904 - accuracy: 0.9992 - val_loss: 1.3463 - val_accuracy: 0.6719\nEpoch 37/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0822 - accuracy: 0.9996 - val_loss: 1.3285 - val_accuracy: 0.6758\nEpoch 38/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0748 - accuracy: 0.9998 - val_loss: 1.3248 - val_accuracy: 0.6758\nEpoch 39/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0687 - accuracy: 0.9998 - val_loss: 1.3176 - val_accuracy: 0.6828\nEpoch 40/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 1.3097 - val_accuracy: 0.6852\nEpoch 41/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 1.3003 - val_accuracy: 0.6836\nEpoch 42/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.6836\nEpoch 43/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 1.2813 - val_accuracy: 0.6906\nEpoch 44/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.6891\nEpoch 45/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.6891\nEpoch 46/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 1.2683 - val_accuracy: 0.6883\nEpoch 47/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.6914\nEpoch 48/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.6938\nEpoch 49/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.2537 - val_accuracy: 0.6945\nEpoch 50/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.2525 - val_accuracy: 0.7023\nEpoch 51/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.6961\nEpoch 52/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.7008\nEpoch 53/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.7008\nEpoch 54/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.7008\nEpoch 55/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.7016\nEpoch 56/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.2302 - val_accuracy: 0.7016\nEpoch 57/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.7078\nEpoch 58/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.7078\nEpoch 59/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2186 - val_accuracy: 0.7094\nEpoch 60/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2166 - val_accuracy: 0.7117\nEpoch 61/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2087 - val_accuracy: 0.7141\nEpoch 62/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.7117\nEpoch 63/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2103 - val_accuracy: 0.7133\nEpoch 64/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.2046 - val_accuracy: 0.7141\nEpoch 65/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.2010 - val_accuracy: 0.7188\nEpoch 66/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.7172\nEpoch 67/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.7180\nEpoch 68/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1936 - val_accuracy: 0.7211\nEpoch 69/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.1948 - val_accuracy: 0.7195\nEpoch 70/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.7188\nEpoch 71/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.7203\nEpoch 72/99\n81/81 [==============================] - 10s 129ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.7164\nEpoch 73/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.7188\nEpoch 74/99\n81/81 [==============================] - 11s 130ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1861 - val_accuracy: 0.7203\nEpoch 75/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1846 - val_accuracy: 0.7234\nEpoch 76/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1807 - val_accuracy: 0.7258\nEpoch 77/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.7234\nEpoch 78/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.1791 - val_accuracy: 0.7258\nEpoch 79/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.1754 - val_accuracy: 0.7219\nEpoch 80/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.7227\nEpoch 81/99\n81/81 [==============================] - 11s 133ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1739 - val_accuracy: 0.7250\nEpoch 82/99\n81/81 [==============================] - 11s 133ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1734 - val_accuracy: 0.7227\nEpoch 83/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.7281\nEpoch 84/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1722 - val_accuracy: 0.7242\nEpoch 85/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.7266\nEpoch 86/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.7234\nEpoch 87/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1675 - val_accuracy: 0.7289\nEpoch 88/99\n81/81 [==============================] - 11s 133ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1683 - val_accuracy: 0.7266\nEpoch 89/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.7258\nEpoch 90/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1647 - val_accuracy: 0.7297\nEpoch 91/99\n81/81 [==============================] - 11s 133ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.7312\nEpoch 92/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.7273\nEpoch 93/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1662 - val_accuracy: 0.7281\nEpoch 94/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.7344\nEpoch 95/99\n81/81 [==============================] - 11s 131ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.7289\nEpoch 96/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1587 - val_accuracy: 0.7305\nEpoch 97/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.7312\nEpoch 98/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.7312\nEpoch 99/99\n81/81 [==============================] - 11s 132ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.7328\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7b4524f30160>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"preds = np.argmax(model_densenet.predict(valid),axis = 1)\nprint(preds[:10])\nprint(np.argmax(y_valid[:10],axis = 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:44:23.311492Z","iopub.execute_input":"2025-08-02T21:44:23.311801Z","iopub.status.idle":"2025-08-02T21:44:26.990198Z","shell.execute_reply.started":"2025-08-02T21:44:23.311776Z","shell.execute_reply":"2025-08-02T21:44:26.989436Z"}},"outputs":[{"name":"stdout","text":"20/20 [==============================] - 4s 98ms/step\n[34 65 17  4  4 30 10 40 27 54]\n[47 65 17 43  4 30 10 40 27 54]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"modelbase_inference = Model(inputs=basemodel1.input,\n                outputs = model_densenet.get_layer(\"dense_before_arcface\").output)\nout = modelbase_inference.output\nout = Dense(units=512,activation = 'relu')(out)\nout = Dropout(rate = 0.5)(out)\nout = Dense(units=128,activation = 'relu')(out)\nout = Dense(units = 75,activation = 'softmax')(out)\nmodel_inference = Model(inputs = basemodel1.input, outputs = out)\nfor i in modelbase_inference.layers:\n    i.trainable = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:44:59.964992Z","iopub.execute_input":"2025-08-02T21:44:59.965333Z","iopub.status.idle":"2025-08-02T21:45:00.051006Z","shell.execute_reply.started":"2025-08-02T21:44:59.965307Z","shell.execute_reply":"2025-08-02T21:45:00.050336Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"lr = 0.0001\nEpochs = 40\nbatch_size = 64\nimport tensorflow as tf\nimport keras\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                initial_learning_rate = lr,\n                decay_steps = 10000,\n                decay_rate = 0.9)\nopt = Adam(learning_rate = lr_schedule)\nmodel_inference.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\nmodel_inference.fit(gen.flow(X_train,y_train,batch_size = batch_size),\n          steps_per_epoch = len(X_train)//batch_size,\n          validation_data = (X_valid,y_valid),\n          validation_steps = len(X_valid)/batch_size,\n         epochs = Epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T21:45:02.862496Z","iopub.execute_input":"2025-08-02T21:45:02.862844Z","iopub.status.idle":"2025-08-02T22:21:46.469761Z","shell.execute_reply.started":"2025-08-02T21:45:02.862817Z","shell.execute_reply":"2025-08-02T22:21:46.468988Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/40\n81/81 [==============================] - 65s 723ms/step - loss: 4.5817 - accuracy: 0.0175 - val_loss: 4.2129 - val_accuracy: 0.0385\nEpoch 2/40\n81/81 [==============================] - 55s 677ms/step - loss: 4.2532 - accuracy: 0.0425 - val_loss: 4.0193 - val_accuracy: 0.0985\nEpoch 3/40\n81/81 [==============================] - 55s 674ms/step - loss: 4.0397 - accuracy: 0.0804 - val_loss: 3.8300 - val_accuracy: 0.1631\nEpoch 4/40\n81/81 [==============================] - 54s 669ms/step - loss: 3.8542 - accuracy: 0.1264 - val_loss: 3.6168 - val_accuracy: 0.2262\nEpoch 5/40\n81/81 [==============================] - 55s 673ms/step - loss: 3.6622 - accuracy: 0.1675 - val_loss: 3.3858 - val_accuracy: 0.2823\nEpoch 6/40\n81/81 [==============================] - 55s 675ms/step - loss: 3.4083 - accuracy: 0.2105 - val_loss: 3.1459 - val_accuracy: 0.3300\nEpoch 7/40\n81/81 [==============================] - 55s 677ms/step - loss: 3.2624 - accuracy: 0.2325 - val_loss: 2.9247 - val_accuracy: 0.3692\nEpoch 8/40\n81/81 [==============================] - 55s 673ms/step - loss: 3.0448 - accuracy: 0.2791 - val_loss: 2.7239 - val_accuracy: 0.4069\nEpoch 9/40\n81/81 [==============================] - 54s 672ms/step - loss: 2.8606 - accuracy: 0.3067 - val_loss: 2.5506 - val_accuracy: 0.4154\nEpoch 10/40\n81/81 [==============================] - 55s 677ms/step - loss: 2.7063 - accuracy: 0.3381 - val_loss: 2.4074 - val_accuracy: 0.4369\nEpoch 11/40\n81/81 [==============================] - 55s 680ms/step - loss: 2.5860 - accuracy: 0.3542 - val_loss: 2.2955 - val_accuracy: 0.4462\nEpoch 12/40\n81/81 [==============================] - 56s 686ms/step - loss: 2.4791 - accuracy: 0.3755 - val_loss: 2.1997 - val_accuracy: 0.4638\nEpoch 13/40\n81/81 [==============================] - 55s 674ms/step - loss: 2.3782 - accuracy: 0.3924 - val_loss: 2.1215 - val_accuracy: 0.4823\nEpoch 14/40\n81/81 [==============================] - 52s 641ms/step - loss: 2.2791 - accuracy: 0.3969 - val_loss: 2.0512 - val_accuracy: 0.4962\nEpoch 15/40\n81/81 [==============================] - 55s 672ms/step - loss: 2.2477 - accuracy: 0.4095 - val_loss: 2.0000 - val_accuracy: 0.5000\nEpoch 16/40\n81/81 [==============================] - 55s 677ms/step - loss: 2.1733 - accuracy: 0.4222 - val_loss: 1.9548 - val_accuracy: 0.5108\nEpoch 17/40\n81/81 [==============================] - 55s 684ms/step - loss: 2.1131 - accuracy: 0.4440 - val_loss: 1.9172 - val_accuracy: 0.5123\nEpoch 18/40\n81/81 [==============================] - 55s 680ms/step - loss: 2.0430 - accuracy: 0.4580 - val_loss: 1.8798 - val_accuracy: 0.5131\nEpoch 19/40\n81/81 [==============================] - 53s 648ms/step - loss: 2.0428 - accuracy: 0.4526 - val_loss: 1.8503 - val_accuracy: 0.5200\nEpoch 20/40\n81/81 [==============================] - 56s 687ms/step - loss: 1.9925 - accuracy: 0.4676 - val_loss: 1.8268 - val_accuracy: 0.5246\nEpoch 21/40\n81/81 [==============================] - 56s 690ms/step - loss: 1.9338 - accuracy: 0.4826 - val_loss: 1.7999 - val_accuracy: 0.5331\nEpoch 22/40\n81/81 [==============================] - 56s 691ms/step - loss: 1.9271 - accuracy: 0.4798 - val_loss: 1.7775 - val_accuracy: 0.5400\nEpoch 23/40\n81/81 [==============================] - 56s 695ms/step - loss: 1.9277 - accuracy: 0.4820 - val_loss: 1.7636 - val_accuracy: 0.5454\nEpoch 24/40\n81/81 [==============================] - 55s 678ms/step - loss: 1.8584 - accuracy: 0.4902 - val_loss: 1.7493 - val_accuracy: 0.5462\nEpoch 25/40\n81/81 [==============================] - 55s 676ms/step - loss: 1.8224 - accuracy: 0.4948 - val_loss: 1.7320 - val_accuracy: 0.5446\nEpoch 26/40\n81/81 [==============================] - 54s 668ms/step - loss: 1.8328 - accuracy: 0.4966 - val_loss: 1.7185 - val_accuracy: 0.5492\nEpoch 27/40\n81/81 [==============================] - 54s 668ms/step - loss: 1.7906 - accuracy: 0.5071 - val_loss: 1.7019 - val_accuracy: 0.5569\nEpoch 28/40\n81/81 [==============================] - 55s 677ms/step - loss: 1.7830 - accuracy: 0.5106 - val_loss: 1.6926 - val_accuracy: 0.5592\nEpoch 29/40\n81/81 [==============================] - 56s 688ms/step - loss: 1.7371 - accuracy: 0.5192 - val_loss: 1.6796 - val_accuracy: 0.5631\nEpoch 30/40\n81/81 [==============================] - 55s 676ms/step - loss: 1.7279 - accuracy: 0.5324 - val_loss: 1.6691 - val_accuracy: 0.5569\nEpoch 31/40\n81/81 [==============================] - 55s 675ms/step - loss: 1.6894 - accuracy: 0.5287 - val_loss: 1.6653 - val_accuracy: 0.5662\nEpoch 32/40\n81/81 [==============================] - 55s 677ms/step - loss: 1.7134 - accuracy: 0.5242 - val_loss: 1.6540 - val_accuracy: 0.5662\nEpoch 33/40\n81/81 [==============================] - 55s 682ms/step - loss: 1.6628 - accuracy: 0.5410 - val_loss: 1.6475 - val_accuracy: 0.5700\nEpoch 34/40\n81/81 [==============================] - 55s 677ms/step - loss: 1.7106 - accuracy: 0.5248 - val_loss: 1.6435 - val_accuracy: 0.5638\nEpoch 35/40\n81/81 [==============================] - 55s 674ms/step - loss: 1.6463 - accuracy: 0.5416 - val_loss: 1.6316 - val_accuracy: 0.5738\nEpoch 36/40\n81/81 [==============================] - 54s 672ms/step - loss: 1.6178 - accuracy: 0.5398 - val_loss: 1.6228 - val_accuracy: 0.5792\nEpoch 37/40\n81/81 [==============================] - 55s 675ms/step - loss: 1.6179 - accuracy: 0.5433 - val_loss: 1.6165 - val_accuracy: 0.5731\nEpoch 38/40\n81/81 [==============================] - 55s 676ms/step - loss: 1.6284 - accuracy: 0.5486 - val_loss: 1.6089 - val_accuracy: 0.5785\nEpoch 39/40\n81/81 [==============================] - 55s 675ms/step - loss: 1.5939 - accuracy: 0.5538 - val_loss: 1.6045 - val_accuracy: 0.5777\nEpoch 40/40\n81/81 [==============================] - 55s 674ms/step - loss: 1.5997 - accuracy: 0.5517 - val_loss: 1.6010 - val_accuracy: 0.5831\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7b44bd721540>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"preds = np.argmax(model_inference.predict(X_valid[:10]),axis = 1)\nprint(preds[:10])\nprint(np.argmax(y_valid[:10],axis = 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T22:23:40.601847Z","iopub.execute_input":"2025-08-02T22:23:40.602163Z","iopub.status.idle":"2025-08-02T22:23:43.381540Z","shell.execute_reply.started":"2025-08-02T22:23:40.602136Z","shell.execute_reply":"2025-08-02T22:23:43.380852Z"}},"outputs":[{"name":"stdout","text":"1/1 [==============================] - 3s 3s/step\n[47 11 17  4  4 30 10 62 27 54]\n[47 65 17 43  4 30 10 40 27 54]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## Model CNN EfficientNetB0","metadata":{}},{"cell_type":"code","source":"basemodel = EfficientNetB0(weights = 'imagenet',include_top = False, input_tensor = Input(shape = (224,224,3)))\nheadmodel = basemodel.output\nheadmodel = AveragePooling2D()(headmodel)\nheadmodel = Flatten()(headmodel)\nheadmodel = Dense(units=512,activation = 'relu')(headmodel)\nheadmodel = Dropout(rate = 0.5)(headmodel)\nheadmodel = Dense(units=128,activation = 'relu')(headmodel)\nheadmodel = Dense(units = 75,activation = 'softmax')(headmodel)\nmodel = Model(inputs = basemodel.input, outputs = headmodel)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T03:23:52.887030Z","iopub.execute_input":"2023-08-22T03:23:52.887724Z","iopub.status.idle":"2023-08-22T03:23:57.577915Z","shell.execute_reply.started":"2023-08-22T03:23:52.887673Z","shell.execute_reply":"2023-08-22T03:23:57.576519Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in basemodel.layers:\n    i.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-22T03:23:57.579264Z","iopub.execute_input":"2023-08-22T03:23:57.579587Z","iopub.status.idle":"2023-08-22T03:23:57.597976Z","shell.execute_reply.started":"2023-08-22T03:23:57.579558Z","shell.execute_reply":"2023-08-22T03:23:57.596496Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = 0.0001\nEpochs = 40\nbatch_size = 64\nimport tensorflow as tf\nimport keras\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                initial_learning_rate = lr,\n                decay_steps = 10000,\n                decay_rate = 0.9)\nopt = Adam(learning_rate = lr_schedule)\nmodel.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\nmodel.fit(gen.flow(X_train,y_train,batch_size = batch_size),\n          steps_per_epoch = len(X_train)//batch_size,\n          validation_data = (X_valid,y_valid),\n          validation_steps = len(X_valid)/batch_size,\n         epochs = Epochs)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T03:23:57.600095Z","iopub.execute_input":"2023-08-22T03:23:57.600594Z","iopub.status.idle":"2023-08-22T04:14:38.127408Z","shell.execute_reply.started":"2023-08-22T03:23:57.600549Z","shell.execute_reply":"2023-08-22T04:14:38.126094Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model CNN EfficientNetV2**","metadata":{}},{"cell_type":"code","source":"basemodel2 = EfficientNetV2L(weights = 'imagenet',include_top = False, input_tensor = Input(shape = (224,224,3)))\nheadmodel2 = basemodel2.output\nheadmodel2 = AveragePooling2D()(headmodel2)\nheadmodel2 = Flatten()(headmodel2)\nheadmodel2 = Dense(units=128,activation = 'relu')(headmodel2)\nheadmodel2 = Dropout(rate = 0.5)(headmodel2)\nheadmodel2 = Dense(units=128,activation = 'relu')(headmodel2)\nheadmodel2 = Dense(units = 75,activation = 'softmax')(headmodel2)\nmodel_v2 = Model(inputs = basemodel2.input, outputs = headmodel2)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T04:14:38.129052Z","iopub.execute_input":"2023-08-22T04:14:38.129539Z","iopub.status.idle":"2023-08-22T04:15:12.165123Z","shell.execute_reply.started":"2023-08-22T04:14:38.129493Z","shell.execute_reply":"2023-08-22T04:15:12.163530Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in basemodel2.layers:\n    i.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-22T04:15:12.166925Z","iopub.execute_input":"2023-08-22T04:15:12.167410Z","iopub.status.idle":"2023-08-22T04:15:12.219276Z","shell.execute_reply.started":"2023-08-22T04:15:12.167360Z","shell.execute_reply":"2023-08-22T04:15:12.218219Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = 0.0001\nEpochs = 8\nbatch_size = 64\nimport tensorflow as tf\nimport keras\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                initial_learning_rate = lr,\n                decay_steps = 10000,\n                decay_rate = 0.9)\nopt = Adam(learning_rate = lr_schedule)\nmodel_v2.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = [keras.metrics.AUC(name = 'auc')])\nmodel_v2.fit(gen.flow(X_train,y_train,batch_size = batch_size),\n          steps_per_epoch = len(X_train)//batch_size,\n          validation_data = (X_valid,y_valid),\n          validation_steps = len(X_valid)/batch_size,\n         epochs = Epochs)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T04:15:12.220456Z","iopub.execute_input":"2023-08-22T04:15:12.221619Z","iopub.status.idle":"2023-08-22T09:46:46.925920Z","shell.execute_reply.started":"2023-08-22T04:15:12.221552Z","shell.execute_reply":"2023-08-22T09:46:46.924402Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test data","metadata":{}},{"cell_type":"code","source":"# = model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.600534Z","iopub.status.idle":"2023-08-22T01:20:16.601598Z","shell.execute_reply.started":"2023-08-22T01:20:16.601373Z","shell.execute_reply":"2023-08-22T01:20:16.601396Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#print(predict[:10])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.602922Z","iopub.status.idle":"2023-08-22T01:20:16.603832Z","shell.execute_reply.started":"2023-08-22T01:20:16.603588Z","shell.execute_reply":"2023-08-22T01:20:16.603627Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predict = np.argmax(predict,axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.605105Z","iopub.status.idle":"2023-08-22T01:20:16.605981Z","shell.execute_reply.started":"2023-08-22T01:20:16.605770Z","shell.execute_reply":"2023-08-22T01:20:16.605793Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predict[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.607302Z","iopub.status.idle":"2023-08-22T01:20:16.608154Z","shell.execute_reply.started":"2023-08-22T01:20:16.607928Z","shell.execute_reply":"2023-08-22T01:20:16.607950Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test_label['label'] = enc.inverse_transform(predict)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.609859Z","iopub.status.idle":"2023-08-22T01:20:16.610280Z","shell.execute_reply.started":"2023-08-22T01:20:16.610080Z","shell.execute_reply":"2023-08-22T01:20:16.610101Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test_label","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.612001Z","iopub.status.idle":"2023-08-22T01:20:16.612405Z","shell.execute_reply.started":"2023-08-22T01:20:16.612210Z","shell.execute_reply":"2023-08-22T01:20:16.612230Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test_label[test_label['filename']=='Image_1.jpg']","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.613559Z","iopub.status.idle":"2023-08-22T01:20:16.614047Z","shell.execute_reply.started":"2023-08-22T01:20:16.613783Z","shell.execute_reply":"2023-08-22T01:20:16.613803Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission = pd.merge(test_set,test_label,how = 'left',on = 'filename')","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.615068Z","iopub.status.idle":"2023-08-22T01:20:16.615450Z","shell.execute_reply.started":"2023-08-22T01:20:16.615260Z","shell.execute_reply":"2023-08-22T01:20:16.615279Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#print(test_set.shape)\n#print(submission.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.617556Z","iopub.status.idle":"2023-08-22T01:20:16.618342Z","shell.execute_reply.started":"2023-08-22T01:20:16.618137Z","shell.execute_reply":"2023-08-22T01:20:16.618158Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.620021Z","iopub.status.idle":"2023-08-22T01:20:16.620406Z","shell.execute_reply.started":"2023-08-22T01:20:16.620216Z","shell.execute_reply":"2023-08-22T01:20:16.620235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission.to_csv('Testing_set.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T01:20:16.621749Z","iopub.status.idle":"2023-08-22T01:20:16.622665Z","shell.execute_reply.started":"2023-08-22T01:20:16.622421Z","shell.execute_reply":"2023-08-22T01:20:16.622444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict1 = 0.2 * model_v2.predict(test_data) + 0.6 * model.predict(test_data) \\\n+ 0.05 * model_densenet.predict(test_data) + 0.05 * model1.predict_proba(test_data1) \\\n+ 0.05 * model2.predict_proba(test_data1) + 0.05 * model3.predict_proba(test_data1)\npredict1 = np.argmax(predict1,axis = 1)\ntest_label['label'] = enc.inverse_transform(predict1)\nsubmission1 = pd.merge(test_set,test_label,how = 'left',on = 'filename')\nsubmission1.to_csv('Testing_set1.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T09:46:46.928991Z","iopub.execute_input":"2023-08-22T09:46:46.929851Z","iopub.status.idle":"2023-08-22T10:10:41.554426Z","shell.execute_reply.started":"2023-08-22T09:46:46.929800Z","shell.execute_reply":"2023-08-22T10:10:41.552910Z"},"trusted":true},"outputs":[],"execution_count":null}]}